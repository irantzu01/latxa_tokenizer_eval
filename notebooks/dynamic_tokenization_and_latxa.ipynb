{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c382fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../dynamic-tokenization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e93823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irantzu/MASTER/WiSe25/Lab Rotation/dynamic-tokenization/dynamic_tokenization_311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tokenizations.dynamic_bpe import Dynamic_BPE\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import torch\n",
    "from zett.utils import get_surface_form_matrix\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866a0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d3e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../dynamic-tokenization\")\n",
    "sys.path.append(\"../dynamic_tokenization_tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d2a7d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForCausalLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load Latxa model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiTZ/latxa-7b-v1.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m latxa_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiTZ/latxa-7b-v1.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatxa model and tokenizer loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForCausalLM' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Latxa model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HiTZ/latxa-7b-v1.2\")\n",
    "latxa_tokenizer = AutoTokenizer.from_pretrained(\"HiTZ/latxa-7b-v1.2\")\n",
    "print(\"Latxa model and tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da462804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hypernetwork\n",
    "hypernet = AutoModel.from_pretrained(\n",
    "    \"benjamin/zett-hypernetwork-Meta-Llama-3-8B-experimental\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "hypernet_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"benjamin/zett-hypernetwork-Meta-Llama-3-8B-experimental\"\n",
    ")\n",
    "\n",
    "# hypernet.config.hf_model_type = \"meta-llama/LlamaForCausalLM\"\n",
    "\n",
    "# orig_forward = hypernet.forward\n",
    "# def patched_forward(*args, **kwargs):\n",
    "#     out = orig_forward(*args, **kwargs)\n",
    "#     if isinstance(out, tuple) and len(out) == 2:\n",
    "#         return out[0], out[1], None\n",
    "#     return out\n",
    "# hypernet.forward = patched_forward\n",
    "\n",
    "# dynamic BPE init\n",
    "dynamic_bpe = Dynamic_BPE(\n",
    "    tokenizer=hypernet_tokenizer,\n",
    "    tokenizer_boundary=\"pretokens\",\n",
    ")\n",
    "\n",
    "# # fix required by Dynamic_BPE for tokenizer.model.config\n",
    "# hypernet_tokenizer.model = type(\"x\", (), {})()\n",
    "# hypernet_tokenizer.model.config = type(\"y\", (), {})()\n",
    "# hypernet_tokenizer.model.config.hf_model_type = \"meta-llama/LlamaForCausalLM\"\n",
    "\n",
    "print(\"Hypernetwork + tokenizer + Dynamic BPE ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b57986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'candidates', 'answer'],\n",
      "        num_rows: 5169\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'question', 'candidates', 'answer'],\n",
      "    num_rows: 5169\n",
      "})\n",
      "['Bi seme-alaba ditu, ..... ederragoak.', '..... , gero, garaipena erraza izango denik!', 'Zein dago zuzen?']\n",
      "[['zenbat eta', 'haiek baino', 'nola edo hala', 'zein baino zein'], ['Ezta pentsatzea ere', 'Ez pentsa', 'Ezta pentsa ere', 'Ez pentsatzea'], ['Alde askoetatik jasan zituen irainak.', 'Atzoko bileran zuzendari izendatu ninduten.', 'Urtearen zehar makina bat ekitaldi antolatzen da herrian.', 'Herritar guztiak erasotu zituzten.']]\n",
      "[3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Load EusProficiency dataset\n",
    "ds = load_dataset(\"HiTZ/EusProficiency\")\n",
    "print(ds)\n",
    "ds = ds[\"test\"]\n",
    "print(ds)\n",
    "ds_questions = ds[\"question\"]\n",
    "print(ds_questions[:3])\n",
    "ds_candidates = ds[\"candidates\"]\n",
    "print(ds_candidates[:3])\n",
    "ds_answers = ds[\"answer\"]\n",
    "print(ds_answers[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6442916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'category', 'difficulty', 'question', 'candidates', 'answer'],\n",
      "        num_rows: 1715\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'category', 'difficulty', 'question', 'candidates', 'answer'],\n",
      "    num_rows: 1715\n",
      "})\n",
      "['Nola bota behar dira honakoak ontzi horietara?', 'Zein da 69 zenbakiaren hurrengoa?', 'Lau sagarrek 400 gr pisatzen badute, zenbat pisatzen du sagar batek?']\n",
      "[['Apurturik', 'Denak lotuta', 'Tapoia kendu gabe', 'Tapoirik gabe'], ['96', '86', '70', '68'], ['Ez dakigu', '150 gr', '75 gr', '100 gr']]\n",
      "[3, 2, 0]\n",
      "['zaila', 'erraza', 'erraza']\n"
     ]
    }
   ],
   "source": [
    "ds_EusTrivia = load_dataset(\"HiTZ/EusTrivia\")\n",
    "print(ds_EusTrivia)\n",
    "ds_EusTrivia = ds_EusTrivia[\"test\"]\n",
    "print(ds_EusTrivia)\n",
    "ds_EusTrivia_questions = ds_EusTrivia[\"question\"]\n",
    "print(ds_EusTrivia_questions[:3])\n",
    "ds_EusTrivia_candidates = ds_EusTrivia[\"candidates\"]\n",
    "print(ds_EusTrivia_candidates[:3])\n",
    "ds_EusTrivia_answers = ds_EusTrivia[\"answer\"]\n",
    "print(ds_EusTrivia_answers[:3])\n",
    "ds_EusTrivia_difficulty = ds_EusTrivia[\"difficulty\"]\n",
    "print(ds_EusTrivia_difficulty[:3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeeb13cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'context', 'question', 'candidates', 'answer'],\n",
      "        num_rows: 352\n",
      "    })\n",
      "})\n",
      "['Bizitzeko baliabidea\\n\\n\\n\\n\\nUra gero eta baliabide urriagoa denez, eskaria eta zarrastelkeria murriztu egin behar dira. Baina nola?\\n\\nUra gizakion eta naturaren bitartekoa da eta gure eguneroko bizitzan eta gure imajinazioan dago. Mundua mundu denetik, urak gizarte eraikuntza ikusgarriak eta banaketari lotutako gatazka ugari eragin ditu. Baina, munduko pertsona gehienek ez dute ur faltarik izan eta horregatik uraren erabilgarritasunak mugarik ez duela iruditzen zaie. Industriakoek, nekazariek, kontsumitzaile arruntek ura neurririk gabe xahutzen jarraitzen dute. Hala ere, eskaintzak behera eta eskariak gora egin dutenez, edonork daki jarrera aldatzeko ordua iritsi dela.\\n\\nPertsona gehienak ez dira ondorengo honetaz ohartzen: ur geza baliabide oso urria dela. Munduko mapetan nagusi den kolore urdin horrek asko eta asko engainatu egiten ditu. Ez dakite planetako uraren %97,5 gazia dela. Ezta ur geza –gainerako %2,5– neurri handi batean ezin dela erabili ere: %70 Antartikoko eta Groenlandiako izotz bloke handietan dago eta gainerakoaren zatirik handiena, berriz, lurrean hezetasun gisa. Hau da, Lurreko ur guztiaren %0,007 baino ezin da erraz eskuratu.\\n\\nMendeetan zehar, hazkunde demografikoak eta giza jarduerak baliabide preziatu hori askoz ere \"ahulagoa\" egin dute. 1990. eta 1995. urteen artean ur erauzketa sei aldiz baino gehiago hazi zen, hau da, populazioaren hazkundearen erritmoa baino bi aldiz azkarrago. Presio gorakor horrek urritasun arriskuak areagotu egin ditu. Ur gezaren kopuruaren eta munduko populazioaren arteko erlazioa finkatuz gero, ikus dezakegu uraren batez besteko erabilgarritasuna ez dela nahikoa. Baina eskualde ahulenetan 460 milioi lagun inguruk (planetako biztanleen %8) urik ez dutela kalkulatu da. Munduko populazioaren laurdenak egoera horretarantz jotzeko arriskua du. Ez bada ezer egiten, adituek aurreikusten dutenez, gizakien bi herenek ur eskasia izango dute 2025. urtea baino lehen.\\n\\nBaliabideak banatzeko orduan halako aldeak izatearen ondorioz, kontsumo mailetan ere izugarrizko aldeak daude: landa-eskualdean bizi den malgatxe batek eguneko 10 litro ur erabiltzen ditu, hau da, bizitzeko minimoa; frantziar batek 150 litro eta iparramerikar batek 425 litro. Erabilgarritasun arazoei kalitatearen degradazio kezkagarria gehitu behar zaie. Eskualde batzuetan ura oso kutsatuta dago eta ezin da erabili, ezta industrian ere.\\n\\nEgoera oso larria da hiri-eskualdeetan, eta premiak ere oso handiak. Gizateriaren historian lehenengo aldiz, hiriek landa-eskualdeek baino biztanleria handiagoa izango dute, eta horren ondorioz, ur kantitate handiagoak kontsumituko dituzte. Hirien hazkunde hori dela eta, lehia handiagoa izango da uraren erabiltzaile mota desberdinen artean. Gaur egun nekazaritzak munduan kontsumitzen den uraren %69 hartzen du, industriak %23 eta familiek %8. Garapen bidean dauden herrietan nekazaritzari dagokion kontsumoa %80koa ere izan daiteke.\\n\\nLuzaroan aurreikusi zen uraren eskariaren igoera arazo teknikoa izango zela. Eta, beraz, konponbide teknikoak proposatu ziren: urtegi gehiago egitea, itsasoko ura gatzgabetzea, etab. Ideiarik bitxienak aipatu ziren, esate baterako, icebergak zatitu eta atoian eramatea. Gaur egun konponbide teknikoen mugak agerian geratu dira. Adibidez, urtegi gehiago egitea oso garestia da, lekurik errentagarrienak jada erabili izan baitira. Urtegi gehiago egitearen kontrako argudio sozioekologikoak ere badira: milioika pertsonari euren ingurune naturala kentzen zaie eta ekosistemak kaltetu egiten dira.\\n\\nHidrologoen eta ingeniarien ezintasun gero eta handiagoaren aurrean adostasuna sortu da: eskaintza handitu ezin denez –horrek herrialde askori kostu handiak ekarriko lizkieke, aurreikusitako eskaria ikaragarri haztea eta zarrastelkeria mugatu egin behar dira: ureztatze sistemen eraginkortasunik ezaren ondorioz sortzen diren galerak kontsumitzen den uraren %60 inguru direla uste da.\\n\\nEkonomilariek, beraz, urari buruzko eztabaida bizian sartu behar izan dute. Zera aipatzen dute: baliabide horren \"zentzuzko erabilera\" inposatzeko, hau da, ura xahutzea saihestu eta kalitatea bermatzeko, kontsumitzaileei ordainarazi egin behar zaiela. “Ezta pentsatu ere!”, erantzuten dute uraren doakotasunaren aldekoek; ura kultura askotan \"zeruko dohaintzat\" jotzen dute. “Eta behartsuak?”, galdetzen dute giza eskubideen eta ura izateko eskubidearen defendatzaileek. Beste galdera garrantzitsu batzuek eztabaida biziak sorrarazten dituzte: nola kalkulatu behar da uraren \"benetako prezioa\"? Nor arduratu beharko litzateke ura merkaturatzeaz?\\n\\nNahiz eta kontrako iritziak eta zalantzak ugari izan, uraren doakotasun printzipioa zalantzan ipini da, besterik gabe. Askoren ustez, gaur egun ura saldu eta erosi egiten den merkantzia da. Baina elkarbanatutako baliabide horren kudeaketa ezin da gelditu irabazi-legeen menpe bakarrik. Gizarte zibileko agente ugari –GKE, ikertzaileak, talde komunitarioak, etab.– ekin eta ekin ari dira uraren kudeaketaren dimentsio sozial eta kulturalak kontuan har daitezen. Mundu Bankua ere (pribatizazioaren bultzatzaile nagusia), alderdi horren inguruan zuhur dago. Sektore publikoaren eta pribatuaren artean azken urteotan gero eta gehiago diren taldeen aberastasuna onartu egiten du. Badirudi estatua baino ez dela zuzentasuna bermatzeko gai, eta baita partehartzaileen artean epaile gisa aritzeko ere. Partehartzaileak hauek dira: kontsumitzaile taldeak, enpresa pribatuak eta erakunde publikoak.\\n\\nEdonola ere, behar-beharrezkoa da uraren kudeaketa arautzeko sistemak sortzea, baina ez finantza irizpideen arabera bakarrik. Ehunka milioi pertsonari ura izateko eskubidea ukatzen ez bazaie, behintzat.', 'Bizitzeko baliabidea\\n\\n\\n\\n\\nUra gero eta baliabide urriagoa denez, eskaria eta zarrastelkeria murriztu egin behar dira. Baina nola?\\n\\nUra gizakion eta naturaren bitartekoa da eta gure eguneroko bizitzan eta gure imajinazioan dago. Mundua mundu denetik, urak gizarte eraikuntza ikusgarriak eta banaketari lotutako gatazka ugari eragin ditu. Baina, munduko pertsona gehienek ez dute ur faltarik izan eta horregatik uraren erabilgarritasunak mugarik ez duela iruditzen zaie. Industriakoek, nekazariek, kontsumitzaile arruntek ura neurririk gabe xahutzen jarraitzen dute. Hala ere, eskaintzak behera eta eskariak gora egin dutenez, edonork daki jarrera aldatzeko ordua iritsi dela.\\n\\nPertsona gehienak ez dira ondorengo honetaz ohartzen: ur geza baliabide oso urria dela. Munduko mapetan nagusi den kolore urdin horrek asko eta asko engainatu egiten ditu. Ez dakite planetako uraren %97,5 gazia dela. Ezta ur geza –gainerako %2,5– neurri handi batean ezin dela erabili ere: %70 Antartikoko eta Groenlandiako izotz bloke handietan dago eta gainerakoaren zatirik handiena, berriz, lurrean hezetasun gisa. Hau da, Lurreko ur guztiaren %0,007 baino ezin da erraz eskuratu.\\n\\nMendeetan zehar, hazkunde demografikoak eta giza jarduerak baliabide preziatu hori askoz ere \"ahulagoa\" egin dute. 1990. eta 1995. urteen artean ur erauzketa sei aldiz baino gehiago hazi zen, hau da, populazioaren hazkundearen erritmoa baino bi aldiz azkarrago. Presio gorakor horrek urritasun arriskuak areagotu egin ditu. Ur gezaren kopuruaren eta munduko populazioaren arteko erlazioa finkatuz gero, ikus dezakegu uraren batez besteko erabilgarritasuna ez dela nahikoa. Baina eskualde ahulenetan 460 milioi lagun inguruk (planetako biztanleen %8) urik ez dutela kalkulatu da. Munduko populazioaren laurdenak egoera horretarantz jotzeko arriskua du. Ez bada ezer egiten, adituek aurreikusten dutenez, gizakien bi herenek ur eskasia izango dute 2025. urtea baino lehen.\\n\\nBaliabideak banatzeko orduan halako aldeak izatearen ondorioz, kontsumo mailetan ere izugarrizko aldeak daude: landa-eskualdean bizi den malgatxe batek eguneko 10 litro ur erabiltzen ditu, hau da, bizitzeko minimoa; frantziar batek 150 litro eta iparramerikar batek 425 litro. Erabilgarritasun arazoei kalitatearen degradazio kezkagarria gehitu behar zaie. Eskualde batzuetan ura oso kutsatuta dago eta ezin da erabili, ezta industrian ere.\\n\\nEgoera oso larria da hiri-eskualdeetan, eta premiak ere oso handiak. Gizateriaren historian lehenengo aldiz, hiriek landa-eskualdeek baino biztanleria handiagoa izango dute, eta horren ondorioz, ur kantitate handiagoak kontsumituko dituzte. Hirien hazkunde hori dela eta, lehia handiagoa izango da uraren erabiltzaile mota desberdinen artean. Gaur egun nekazaritzak munduan kontsumitzen den uraren %69 hartzen du, industriak %23 eta familiek %8. Garapen bidean dauden herrietan nekazaritzari dagokion kontsumoa %80koa ere izan daiteke.\\n\\nLuzaroan aurreikusi zen uraren eskariaren igoera arazo teknikoa izango zela. Eta, beraz, konponbide teknikoak proposatu ziren: urtegi gehiago egitea, itsasoko ura gatzgabetzea, etab. Ideiarik bitxienak aipatu ziren, esate baterako, icebergak zatitu eta atoian eramatea. Gaur egun konponbide teknikoen mugak agerian geratu dira. Adibidez, urtegi gehiago egitea oso garestia da, lekurik errentagarrienak jada erabili izan baitira. Urtegi gehiago egitearen kontrako argudio sozioekologikoak ere badira: milioika pertsonari euren ingurune naturala kentzen zaie eta ekosistemak kaltetu egiten dira.\\n\\nHidrologoen eta ingeniarien ezintasun gero eta handiagoaren aurrean adostasuna sortu da: eskaintza handitu ezin denez –horrek herrialde askori kostu handiak ekarriko lizkieke, aurreikusitako eskaria ikaragarri haztea eta zarrastelkeria mugatu egin behar dira: ureztatze sistemen eraginkortasunik ezaren ondorioz sortzen diren galerak kontsumitzen den uraren %60 inguru direla uste da.\\n\\nEkonomilariek, beraz, urari buruzko eztabaida bizian sartu behar izan dute. Zera aipatzen dute: baliabide horren \"zentzuzko erabilera\" inposatzeko, hau da, ura xahutzea saihestu eta kalitatea bermatzeko, kontsumitzaileei ordainarazi egin behar zaiela. “Ezta pentsatu ere!”, erantzuten dute uraren doakotasunaren aldekoek; ura kultura askotan \"zeruko dohaintzat\" jotzen dute. “Eta behartsuak?”, galdetzen dute giza eskubideen eta ura izateko eskubidearen defendatzaileek. Beste galdera garrantzitsu batzuek eztabaida biziak sorrarazten dituzte: nola kalkulatu behar da uraren \"benetako prezioa\"? Nor arduratu beharko litzateke ura merkaturatzeaz?\\n\\nNahiz eta kontrako iritziak eta zalantzak ugari izan, uraren doakotasun printzipioa zalantzan ipini da, besterik gabe. Askoren ustez, gaur egun ura saldu eta erosi egiten den merkantzia da. Baina elkarbanatutako baliabide horren kudeaketa ezin da gelditu irabazi-legeen menpe bakarrik. Gizarte zibileko agente ugari –GKE, ikertzaileak, talde komunitarioak, etab.– ekin eta ekin ari dira uraren kudeaketaren dimentsio sozial eta kulturalak kontuan har daitezen. Mundu Bankua ere (pribatizazioaren bultzatzaile nagusia), alderdi horren inguruan zuhur dago. Sektore publikoaren eta pribatuaren artean azken urteotan gero eta gehiago diren taldeen aberastasuna onartu egiten du. Badirudi estatua baino ez dela zuzentasuna bermatzeko gai, eta baita partehartzaileen artean epaile gisa aritzeko ere. Partehartzaileak hauek dira: kontsumitzaile taldeak, enpresa pribatuak eta erakunde publikoak.\\n\\nEdonola ere, behar-beharrezkoa da uraren kudeaketa arautzeko sistemak sortzea, baina ez finantza irizpideen arabera bakarrik. Ehunka milioi pertsonari ura izateko eskubidea ukatzen ez bazaie, behintzat.', 'Bizitzeko baliabidea\\n\\n\\n\\n\\nUra gero eta baliabide urriagoa denez, eskaria eta zarrastelkeria murriztu egin behar dira. Baina nola?\\n\\nUra gizakion eta naturaren bitartekoa da eta gure eguneroko bizitzan eta gure imajinazioan dago. Mundua mundu denetik, urak gizarte eraikuntza ikusgarriak eta banaketari lotutako gatazka ugari eragin ditu. Baina, munduko pertsona gehienek ez dute ur faltarik izan eta horregatik uraren erabilgarritasunak mugarik ez duela iruditzen zaie. Industriakoek, nekazariek, kontsumitzaile arruntek ura neurririk gabe xahutzen jarraitzen dute. Hala ere, eskaintzak behera eta eskariak gora egin dutenez, edonork daki jarrera aldatzeko ordua iritsi dela.\\n\\nPertsona gehienak ez dira ondorengo honetaz ohartzen: ur geza baliabide oso urria dela. Munduko mapetan nagusi den kolore urdin horrek asko eta asko engainatu egiten ditu. Ez dakite planetako uraren %97,5 gazia dela. Ezta ur geza –gainerako %2,5– neurri handi batean ezin dela erabili ere: %70 Antartikoko eta Groenlandiako izotz bloke handietan dago eta gainerakoaren zatirik handiena, berriz, lurrean hezetasun gisa. Hau da, Lurreko ur guztiaren %0,007 baino ezin da erraz eskuratu.\\n\\nMendeetan zehar, hazkunde demografikoak eta giza jarduerak baliabide preziatu hori askoz ere \"ahulagoa\" egin dute. 1990. eta 1995. urteen artean ur erauzketa sei aldiz baino gehiago hazi zen, hau da, populazioaren hazkundearen erritmoa baino bi aldiz azkarrago. Presio gorakor horrek urritasun arriskuak areagotu egin ditu. Ur gezaren kopuruaren eta munduko populazioaren arteko erlazioa finkatuz gero, ikus dezakegu uraren batez besteko erabilgarritasuna ez dela nahikoa. Baina eskualde ahulenetan 460 milioi lagun inguruk (planetako biztanleen %8) urik ez dutela kalkulatu da. Munduko populazioaren laurdenak egoera horretarantz jotzeko arriskua du. Ez bada ezer egiten, adituek aurreikusten dutenez, gizakien bi herenek ur eskasia izango dute 2025. urtea baino lehen.\\n\\nBaliabideak banatzeko orduan halako aldeak izatearen ondorioz, kontsumo mailetan ere izugarrizko aldeak daude: landa-eskualdean bizi den malgatxe batek eguneko 10 litro ur erabiltzen ditu, hau da, bizitzeko minimoa; frantziar batek 150 litro eta iparramerikar batek 425 litro. Erabilgarritasun arazoei kalitatearen degradazio kezkagarria gehitu behar zaie. Eskualde batzuetan ura oso kutsatuta dago eta ezin da erabili, ezta industrian ere.\\n\\nEgoera oso larria da hiri-eskualdeetan, eta premiak ere oso handiak. Gizateriaren historian lehenengo aldiz, hiriek landa-eskualdeek baino biztanleria handiagoa izango dute, eta horren ondorioz, ur kantitate handiagoak kontsumituko dituzte. Hirien hazkunde hori dela eta, lehia handiagoa izango da uraren erabiltzaile mota desberdinen artean. Gaur egun nekazaritzak munduan kontsumitzen den uraren %69 hartzen du, industriak %23 eta familiek %8. Garapen bidean dauden herrietan nekazaritzari dagokion kontsumoa %80koa ere izan daiteke.\\n\\nLuzaroan aurreikusi zen uraren eskariaren igoera arazo teknikoa izango zela. Eta, beraz, konponbide teknikoak proposatu ziren: urtegi gehiago egitea, itsasoko ura gatzgabetzea, etab. Ideiarik bitxienak aipatu ziren, esate baterako, icebergak zatitu eta atoian eramatea. Gaur egun konponbide teknikoen mugak agerian geratu dira. Adibidez, urtegi gehiago egitea oso garestia da, lekurik errentagarrienak jada erabili izan baitira. Urtegi gehiago egitearen kontrako argudio sozioekologikoak ere badira: milioika pertsonari euren ingurune naturala kentzen zaie eta ekosistemak kaltetu egiten dira.\\n\\nHidrologoen eta ingeniarien ezintasun gero eta handiagoaren aurrean adostasuna sortu da: eskaintza handitu ezin denez –horrek herrialde askori kostu handiak ekarriko lizkieke, aurreikusitako eskaria ikaragarri haztea eta zarrastelkeria mugatu egin behar dira: ureztatze sistemen eraginkortasunik ezaren ondorioz sortzen diren galerak kontsumitzen den uraren %60 inguru direla uste da.\\n\\nEkonomilariek, beraz, urari buruzko eztabaida bizian sartu behar izan dute. Zera aipatzen dute: baliabide horren \"zentzuzko erabilera\" inposatzeko, hau da, ura xahutzea saihestu eta kalitatea bermatzeko, kontsumitzaileei ordainarazi egin behar zaiela. “Ezta pentsatu ere!”, erantzuten dute uraren doakotasunaren aldekoek; ura kultura askotan \"zeruko dohaintzat\" jotzen dute. “Eta behartsuak?”, galdetzen dute giza eskubideen eta ura izateko eskubidearen defendatzaileek. Beste galdera garrantzitsu batzuek eztabaida biziak sorrarazten dituzte: nola kalkulatu behar da uraren \"benetako prezioa\"? Nor arduratu beharko litzateke ura merkaturatzeaz?\\n\\nNahiz eta kontrako iritziak eta zalantzak ugari izan, uraren doakotasun printzipioa zalantzan ipini da, besterik gabe. Askoren ustez, gaur egun ura saldu eta erosi egiten den merkantzia da. Baina elkarbanatutako baliabide horren kudeaketa ezin da gelditu irabazi-legeen menpe bakarrik. Gizarte zibileko agente ugari –GKE, ikertzaileak, talde komunitarioak, etab.– ekin eta ekin ari dira uraren kudeaketaren dimentsio sozial eta kulturalak kontuan har daitezen. Mundu Bankua ere (pribatizazioaren bultzatzaile nagusia), alderdi horren inguruan zuhur dago. Sektore publikoaren eta pribatuaren artean azken urteotan gero eta gehiago diren taldeen aberastasuna onartu egiten du. Badirudi estatua baino ez dela zuzentasuna bermatzeko gai, eta baita partehartzaileen artean epaile gisa aritzeko ere. Partehartzaileak hauek dira: kontsumitzaile taldeak, enpresa pribatuak eta erakunde publikoak.\\n\\nEdonola ere, behar-beharrezkoa da uraren kudeaketa arautzeko sistemak sortzea, baina ez finantza irizpideen arabera bakarrik. Ehunka milioi pertsonari ura izateko eskubidea ukatzen ez bazaie, behintzat.']\n",
      "['Urarekiko jarrera dela-eta, zer dio testuak?', 'Zer dio planetako ur gezari buruz?', 'Une honetako kalkuluen arabera']\n",
      "[['Eskaintzak behera eta eskariak gora egin dutenez, argi dagoela jokamoldea aldatu beharrean gaudela.', 'Ez dela aldatuko, munduko pertsona gehienek ur falta somatuagatik.', 'Dagoeneko aldatu dela, eskaintzak behera eta eskariak gora egin dute eta.', 'Munduko pertsona gehienok ez dugu falta izan orain arte; beraz, industriakoek, nekazariek eta kontsumitzaile arruntek neurririk gabe xahutzen jarrai dezakete.'], ['%97,5 da baina %0,007 baino ezin dela erraz eskuratu.', 'Urrezko baliabidea dela pentsatzen duela jende gehienak.', 'Baliabide urria dela, %0,007 besterik ez.', '%70 ezin da erabili Antartikoko eta Groenlandiako izotz bloke handietan dagoelako.'], ['eskualde ahulenetan %8k ez dute urik.', 'munduko populazioaren laurden batek urik gabe geratzeko arriskua du.', 'bost urterik behin ur erauzketa sei aldiz baino gehiago hazten da.', '2025. urtea baino lehen ezer egiten ez bada, hortik aurrera ur eskasia izango dute gizakien bi herenek.']]\n"
     ]
    }
   ],
   "source": [
    "ds_EusReading = load_dataset(\"HiTZ/EusReading\")\n",
    "print(ds_EusReading)\n",
    "ds_EusReading_context = ds_EusReading[\"test\"][\"context\"]\n",
    "print(ds_EusReading_context[:3])\n",
    "ds_EusReading_questions = ds_EusReading[\"test\"][\"question\"]\n",
    "print(ds_EusReading_questions[:3])\n",
    "ds_EusReading_candidates = ds_EusReading[\"test\"][\"candidates\"]\n",
    "print(ds_EusReading_candidates[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c125d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicAugmenter:\n",
    "    \"\"\"\n",
    "    Runtime augmenter that:\n",
    "      - takes dynamic tokens (strings) produced per-batch,\n",
    "      - maps tokens already in latxa_vocab -> keep their ids,\n",
    "      - for new tokens: allocate new ids, predict embeddings with hypernet,\n",
    "        and write those embeddings into model's embedding matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, latxa_tokenizer, hypernet, hypernet_tokenizer, cache_limit=50000):\n",
    "        self.model = model\n",
    "        self.latxa_tokenizer = latxa_tokenizer\n",
    "        self.hypernet = hypernet.to(device)\n",
    "        self.hypernet_tokenizer = hypernet_tokenizer\n",
    "        # base HF vocab mapping (token string -> id)\n",
    "        self.vocab = latxa_tokenizer.get_vocab()\n",
    "        self.reverse_vocab = {v:k for k,v in self.vocab.items()}\n",
    "        self.base_vocab_size = len(self.vocab)\n",
    "        self.cache = OrderedDict()   # token_str -> token_id (preserve insertion order)\n",
    "        self.cache_embeddings = {}   # token_str -> (in_emb_tensor, out_emb_tensor)\n",
    "        self.cache_limit = cache_limit\n",
    "\n",
    "        # Ensure model on device\n",
    "        self.model.to(device)\n",
    "        # we will lazily resize embeddings when needed\n",
    "        self.current_vocab_size = self.base_vocab_size\n",
    "\n",
    "    def _ensure_capacity(self, n_new):\n",
    "        \"\"\"Resize model embeddings to accomodate n_new new ids.\"\"\"\n",
    "        new_size = self.current_vocab_size + n_new\n",
    "        if new_size == self.model.get_input_embeddings().num_embeddings:\n",
    "            return\n",
    "        # HF function to resize embeddings; preserves existing weights and creates new rows\n",
    "        self.model.resize_token_embeddings(new_size)\n",
    "        self.current_vocab_size = new_size\n",
    "\n",
    "    def _predict_embeddings_for_tokens(self, tokens_list):\n",
    "        \"\"\"\n",
    "        Use hypernet to predict embeddings for tokens_list (list of token strings).\n",
    "        Returns dict token -> (pred_in, pred_out) as torch tensors on device.\n",
    "        \"\"\"\n",
    "        # Tokenizer expects list of dicts for get_surface_form_matrix usage\n",
    "        batch_examples = [{\"text\": t} for t in tokens_list]\n",
    "\n",
    "        # Build surface forms matrix (the zett helper expects hypernet_tokenizer)\n",
    "        surfaces = get_surface_form_matrix(\n",
    "            [tokens_list],  # pass as list of list? the function in zett returns arrs; adapt if needed\n",
    "            maxlen=self.hypernet.config.hn_surface_maxlen,\n",
    "            tokenizer_to_use=self.hypernet_tokenizer\n",
    "        )[0]  # get first output if returns tuple\n",
    "\n",
    "        # Build source embeddings matrix from current model (concatenate in/out as in example)\n",
    "        src_emb = torch.cat([\n",
    "            self.model.get_input_embeddings().weight.data,\n",
    "            self.model.get_output_embeddings().weight.data\n",
    "        ], dim=1).to(device)\n",
    "\n",
    "        # surfaces -> hypernet prediction (adapt call to hypernet API)\n",
    "        with torch.no_grad():\n",
    "            pred_in, pred_out, _ = self.hypernet(\n",
    "                torch.from_numpy(surfaces).to(device),\n",
    "                source_embeddings=src_emb\n",
    "            )\n",
    "\n",
    "        # pred_in/out shape: (num_tokens, embedding_dim) etc. Convert to CPU/torch tensors\n",
    "        # Map predicted embeddings to tokens_list order\n",
    "        result = {}\n",
    "        for i, t in enumerate(tokens_list):\n",
    "            result[t] = (pred_in[i].detach().cpu(), pred_out[i].detach().cpu())\n",
    "\n",
    "        return result\n",
    "\n",
    "    def add_and_assign_new_tokens(self, new_token_strs):\n",
    "        \"\"\"\n",
    "        For token strings not in base vocab and not cached:\n",
    "           - predict embeddings with hypernet\n",
    "           - resize model embedding matrix\n",
    "           - write predicted embeddings to new rows\n",
    "        Return mapping token_str -> token_id (global)\n",
    "        \"\"\"\n",
    "        # Filter tokens not already in cache or vocab\n",
    "        to_create = [t for t in new_token_strs if (t not in self.vocab and t not in self.cache)]\n",
    "\n",
    "        if len(to_create) == 0:\n",
    "            # build mapping from cache/vocab for requested tokens\n",
    "            mapping = {}\n",
    "            for t in new_token_strs:\n",
    "                if t in self.vocab:\n",
    "                    mapping[t] = self.vocab[t]\n",
    "                else:\n",
    "                    mapping[t] = self.cache[t]\n",
    "            return mapping\n",
    "\n",
    "        # Predict embeddings with hypernet in chunks if many\n",
    "        CHUNK = 128\n",
    "        predicted = {}\n",
    "        for i in range(0, len(to_create), CHUNK):\n",
    "            chunk = to_create[i:i+CHUNK]\n",
    "            pred_chunk = self._predict_embeddings_for_tokens(chunk)\n",
    "            predicted.update(pred_chunk)\n",
    "\n",
    "        # Now allocate ids and ensure capacity\n",
    "        n_new = len(to_create)\n",
    "        self._ensure_capacity(n_new)\n",
    "\n",
    "        # Write embeddings into the model embedding matrix (on CPU then move)\n",
    "        # We will collect tensors to write to the new rows\n",
    "        input_emb = self.model.get_input_embeddings().weight.data  # on device\n",
    "        output_emb = self.model.get_output_embeddings().weight.data\n",
    "\n",
    "        # assign sequentially at the end\n",
    "        assigned = {}\n",
    "        next_id = self.current_vocab_size - n_new  # first index of newly created rows\n",
    "        # But careful: model.resize_token_embeddings sets current_vocab_size earlier. We stored it there.\n",
    "\n",
    "        # Actually recompute next_id as base + existing cache size\n",
    "        next_id = self.base_vocab_size + len([k for k in self.cache]) \n",
    "\n",
    "        for t in to_create:\n",
    "            in_emb_cpu, out_emb_cpu = predicted[t]  # CPU tensors\n",
    "            in_emb = in_emb_cpu.to(device)\n",
    "            out_emb = out_emb_cpu.to(device)\n",
    "            # new id\n",
    "            new_id = self.base_vocab_size + len(self.cache)\n",
    "            # Append to cache and embeddings\n",
    "            self.cache[t] = new_id\n",
    "            self.cache_embeddings[t] = (in_emb_cpu, out_emb_cpu)\n",
    "            # assign into model weights\n",
    "            # Note: input_emb and output_emb are tensors on device; assign by index\n",
    "            self.model.get_input_embeddings().weight.data[new_id, :] = in_emb\n",
    "            self.model.get_output_embeddings().weight.data[new_id, :] = out_emb\n",
    "            assigned[t] = new_id\n",
    "\n",
    "            # enforce cache limit\n",
    "            if len(self.cache) > self.cache_limit:\n",
    "                # pop oldest\n",
    "                old_token, old_id = self.cache.popitem(last=False)\n",
    "                self.cache_embeddings.pop(old_token, None)\n",
    "                # We do not reclaim embedding rows to keep indices stable (complex). Accept growth or restart.\n",
    "\n",
    "        # Build mapping for all requested tokens (new_token_strs)\n",
    "        mapping = {}\n",
    "        for t in new_token_strs:\n",
    "            if t in self.vocab:\n",
    "                mapping[t] = self.vocab[t]\n",
    "            else:\n",
    "                mapping[t] = self.cache[t]\n",
    "\n",
    "        # Update current_vocab_size if needed\n",
    "        self.current_vocab_size = self.model.get_input_embeddings().num_embeddings\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def tokens_to_ids(self, tokenized_batch):\n",
    "        \"\"\"\n",
    "        Convert a batch tokenized as lists of token strings (dynamic tokens)\n",
    "        into lists of token ids (ints) using base vocab + cache.\n",
    "        tokenized_batch: list[list[str]]\n",
    "        Returns: list[list[int]]\n",
    "        \"\"\"\n",
    "        # gather all unique tokens that are not in base vocab\n",
    "        uniques = set(t for seq in tokenized_batch for t in seq)\n",
    "        new_tokens = [t for t in uniques if t not in self.vocab]\n",
    "        # ensure they are created/assigned\n",
    "        mapping = self.add_and_assign_new_tokens(new_tokens)\n",
    "        # Now map sequences\n",
    "        out_ids = []\n",
    "        for seq in tokenized_batch:\n",
    "            ids = []\n",
    "            for t in seq:\n",
    "                if t in self.vocab:\n",
    "                    ids.append(self.vocab[t])\n",
    "                else:\n",
    "                    ids.append(self.cache[t])\n",
    "            out_ids.append(ids)\n",
    "        return out_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aee1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to normalize dynamic BPE tokens\n",
    "\n",
    "def normalize_dynbpe_tokens(batch_tokens):\n",
    "    cleaned = []\n",
    "    for seq in batch_tokens:\n",
    "        new_seq = []\n",
    "        for tok in seq:\n",
    "            # remove leading GPT whitespace marker if present\n",
    "            if tok.startswith(\"Ġ\"):\n",
    "                tok = tok[1:]\n",
    "\n",
    "            # if token is multi-character, split into characters\n",
    "            # because byte tokenizer expects char-level tokens\n",
    "            for ch in tok:\n",
    "                new_seq.append(ch)\n",
    "        cleaned.append(new_seq)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cbf2195",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DynamicAugmenter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m augmenter \u001b[38;5;241m=\u001b[39m \u001b[43mDynamicAugmenter\u001b[49m(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     latxa_tokenizer\u001b[38;5;241m=\u001b[39mlatxa_tokenizer,\n\u001b[1;32m      4\u001b[0m     hypernet\u001b[38;5;241m=\u001b[39mhypernet,\n\u001b[1;32m      5\u001b[0m     hypernet_tokenizer\u001b[38;5;241m=\u001b[39mhypernet_tokenizer,\n\u001b[1;32m      6\u001b[0m     cache_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), BATCH_SIZE):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DynamicAugmenter' is not defined"
     ]
    }
   ],
   "source": [
    "augmenter = DynamicAugmenter(\n",
    "    model=model,\n",
    "    latxa_tokenizer=latxa_tokenizer,\n",
    "    hypernet=hypernet,\n",
    "    hypernet_tokenizer=hypernet_tokenizer,\n",
    "    cache_limit=50000\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "for i in range(0, len(sentences), BATCH_SIZE):\n",
    "    batch = sentences[i:i+BATCH_SIZE]\n",
    "    print(len(batch))\n",
    "    batch = [s for s in batch if s.strip() != \"\"]\n",
    "    print(len(batch))\n",
    "    examples = [{\"text\": s, \"pretokens\": s.split()} for s in batch]\n",
    "\n",
    "    # 1) Dynamic BPE returns token strings per sentence\n",
    "    dyn_tokens, _, _, _ = dynamic_bpe.tokenize_batch(\n",
    "        batch_examples=examples,\n",
    "        max_nr_merges=30,\n",
    "        mlm=True\n",
    "    )\n",
    "    # dyn_tokens is list[list[str]]\n",
    "    print(\"dyn_tokens example:\", dyn_tokens[0])\n",
    "    # Normalize tokens (remove Ġ, split multi-char into chars)\n",
    "    dyn_tokens = normalize_dynbpe_tokens(dyn_tokens)\n",
    "    print(\"Normalized dyn_tokens example:\", dyn_tokens[0])\n",
    "\n",
    "    # 2) Map tokens to ids, creating new embeddings as needed\n",
    "    batch_ids = augmenter.tokens_to_ids(dyn_tokens)  # list of lists\n",
    "    print(batch_ids[:2])\n",
    "\n",
    "    # 3) Convert to padded tensors for model\n",
    "    # pad with tokenizer.pad_token_id if you have one; else 0\n",
    "    pad_id = latxa_tokenizer.pad_token_id or latxa_tokenizer.eos_token_id\n",
    "    maxlen = max(len(x) for x in batch_ids)\n",
    "    input_ids = torch.full((len(batch_ids), maxlen), pad_id, dtype=torch.long, device=device)\n",
    "    attention_mask = torch.zeros_like(input_ids)\n",
    "    for r, seq in enumerate(batch_ids):\n",
    "        input_ids[r, :len(seq)] = torch.tensor(seq, dtype=torch.long, device=device)\n",
    "        attention_mask[r, :len(seq)] = 1\n",
    "\n",
    "    # 4) Run the model\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    # ... downstream evaluation ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c95eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dynamic Tokenization 3.11",
   "language": "python",
   "name": "dynamic-tokenization-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
